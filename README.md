# ì‹ ìš©ì¹´ë“œ ì‚¬ìš©ì ì—°ì²´ ì˜ˆì¸¡(AI SCHOOL 5ê¸° Semi-project3)
ê¸°ê°„ : 2022-05-02 ~ 2022-05-10  
íŒ€ì› : ê¹€ë‚˜ë¦¬(íŒ€ì¥), ì„œë¯¼ì •, ì´ì°¬ì˜, ì „ì¤€ìš©, ì •ì—°ì¤€

---
## ë°ì´í„° ì¶œì²˜
[ğŸ™ŒDACON ì‹ ìš©ì¹´ë“œ ì‚¬ìš©ì ì—°ì²´ ì˜ˆì¸¡ AI ê²½ì§„ëŒ€íšŒ](https://dacon.io/competitions/official/235713/overview/description)
## ë°ì´í„° í•´ì„¤
<p align="center"><img src="./images/feature_description.png" width="100%" height="100%"></p>

## 01. ë°ì´í„° ì „ì²˜ë¦¬
- **binary**
    - gender
    - car
    - reality
    - work_phone
    - phone
    - email
    - ~~Flag_mobil : drop~~
    - (new) dup: ì—¬ëŸ¬ ì¹´ë“œ ë°œí–‰ ì—¬ë¶€

- **numeric â†’ standard scaler ì ìš©**
    - child_num : ì²˜ë¦¬ ì•ˆí•¨ (ë³´ë¥˜)
    - family_size : ì²˜ë¦¬ ì•ˆí•¨, ì´ìƒì¹˜ ì•ˆì§€ìš°ê³  (ë³´ë¥˜)
    - ~~(new) adult_num : family_size - child_num(logloss ìƒìŠ¹ byì¤€ìš©)~~
    - income_total : log ë³€í™˜ (ì²´í¬í•´ë³¼ê²ƒ)
    - age : np.abs(DAYS_BIRTH) / 365
    - DAYS_EMPLOYED : ì–‘ìˆ˜ëŠ” = 0 , ìŒìˆ˜ëŠ” â†’ np.abs(DAYS_EMPLOYED)
    - begin_MONTH : np.abs(begin_MONTH)
    - (new) cards : í•´ë‹¹ ìœ ì €ê°€ ëª‡ê°œì˜ ì¹´ë“œë¥¼ ì†Œì§€í•˜ê³  ìˆëŠ”ì§€
    
- **categorical**
    - income_type
    - edu_type
    - family_type
    - house_type
    - occyp_type ì°¬ì˜) ë„£ì—ˆì„ ë•Œì™€ ëºì„ ë•Œ ì°¨ì´ê°€ ìˆì–´ì„œ ë¹¼ì„œ í•´ë´„.
        - ê³µí†µ â‡’ ì—…ë¬´ì¼ìˆ˜ 0ì´ë©´ unemployed
        - ë‚˜ë¨¸ì§€ ê²°ì¸¡ì¹˜ ì±„ìš°ëŠ” ë°©ë²• (ë³´ë¥˜)
            - 1ì•ˆ: ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ìš°ê¸°(ì²˜ìŒì— ë‹¤ê°™ì´ ìƒê°í•œ ë°©ì‹)
            - 2ì•ˆ: GBCë¡œ ì¶”ì •í•´ì„œ ì±„ì›Œ ë„£ê¸°
                - ë…ë¦½ë³€ìˆ˜ : ['Age','income_total','income_type','edu_type','house_type', 'work_phone','gender','car','reality']
                - ì¢…ì†ë³€ìˆ˜: â€˜occyp_typeâ€™

### occyp_typeì—´ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° ë…¼ì˜
- occyp_type ê²°ì¸¡ì¹˜ â†’ 8171ê°œ  
- DAYS_EMPLOYEDë¡œ ì–‘ìˆ˜ê°’ ë¬´ì§ ì²˜ë¦¬í•˜ë©´ â†’ 3700ê°œ ë‚¨ìŒ  
- income_typeì—´ì„ ê¸°ë°˜ìœ¼ë¡œ income_typeì˜ valueê°€ Commercial associate ì´ë©´ ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ë§ì€ ì§ì—…ì„ ê²°ì¸¡ì¹˜ì— ë„£ëŠ” í˜•ì‹ìœ¼ë¡œ í•˜ê¸°ë¡œ í•¨  
- ê²°ì¸¡ì¹˜ë¥¼ í¬í•¨í•˜ì§€ì•Šì€ ì—´ì„ GBCë¡œ í•™ìŠµì‹œì¼œ ê²°ì¸¡ì¹˜ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ì±„ì› ìœ¼ë‚˜ ì„±ëŠ¥ì´ ë¯¸ì„¸í•˜ê²Œ ëœ ë‚˜ì™€ì„œ ê¸°ê°í•¨

**occyp_type ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°**  
ê²°ì¸¡ì¹˜ í™•ì¸(missingno)
<p align="center"><img src="./images/ê²°ì¸¡ì¹˜ì±„ìš°ê¸°ì „.png" width="100%" height="100%"></p>   

**ì½”ë“œ**    
```python
# income_typeì˜ value ë¦¬ìŠ¤íŠ¸
income_list = list(set(data_df['income_type'].values))

#income_typeë³„ë¡œ ê°€ì¥ ë§ì€ occyp_typeê°’ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¬
occyp_list = []
for i in income_list:
    occyp_list.append(data_df[data_df['income_type']== i]['occyp_type'].value_counts().index[0])

# ì§ì—… ì¢…ë¥˜ ê²°ì¸¡ì¹˜ income_typeìœ¼ë¡œ ì±„ìš°ê¸°
for i in data_df[data_df['occyp_type'].isnull()].index:
    if data_df['DAYS_EMPLOYED'][i] > 0:
        data_df['occyp_type'][i] = 'Unemployed'
    else:
        for income in income_list:
            if income == data_df['income_type'][i]:
                data_df['occyp_type'][i] = data_df[data_df['income_type']== income]['occyp_type'].value_counts().index[0]
data_df['occyp_type']
```   
ê²°ì¸¡ì¹˜ ì±„ìš´ í›„
<p align="center"><img src="./images/ê²°ì¸¡ì¹˜ì±„ìš´í›„.png" width="100%" height="100%"></p>

## 02. ê° í›„ë³´ featureë³„ loglossë¹„êµ
- adult_num : ê°€ì¡±ìˆ˜ì—ì„œ ì•„ì´ìˆ˜ë¥¼ ëº€ ì„±ì¸ìˆ˜ë¥¼ ë”°ë¡œ ë§Œë“¤ì–´ë³´ì•˜ìŒ  
-> ì„±ëŠ¥ì˜ í° ë³€í™”ê°€ ì—†ì–´ì„œ ì œì™¸
- child_num : í•„ìš”í•¨. ëŒ€ì‹  0, 1, ë‹¤ìë…€ ì¹´í…Œê³ ë¦¬ì»¬ ë³€ìˆ˜ë¡œ ìˆ˜ì • í›„ ì´ìš©
- family_size :  
    - 7ì¸ ì´ˆê³¼ ê°€ì¡±ì€ ì´ìƒì¹˜ë¡œ ë³´ê³  ì œê±°  
    - ì´í›„, 3ê°œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜    
        - 1ëª… : ì‹±ê¸€  
        - 2~3ëª… : í•µê°€ì¡±  
        - 4ëª… ì´ìƒ : ëŒ€ê°€ì¡±  
<p align="center"><img src="./images/ìµœì¢…ì „ì²˜ë¦¬í‘œ.png" width="100%" height="100%"></p>

## 03. Machine Learning
k-foldë¥¼ í™œìš©í•˜ì—¬ í‰ê·  logloss ê³„ì‚°
```python
test_size = 0.2
random_state = 0
num_folds= 5 # test_size = 0.2
str_kf = StratifiedKFold(n_splits = num_folds, shuffle = True, random_state = random_state)
```

**CATBOOST** Classifierëª¨ë¸ì´ ê°€ì¥ ì„±ëŠ¥ì´ ì˜ë‚˜ì˜´
```python
logloss_history = []
accuracy_history = []

for train_index, test_index in str_kf.split(credit_X, credit_Y):
    X_train, X_test = credit_X.loc[train_index], credit_X.loc[test_index]
    y_train, y_test = credit_Y.loc[train_index], credit_Y.loc[test_index]

    x_train_transformed , x_test_transformed, preprocessor = pipe_processing(X_train, X_test)
    new_col_names = get_feature_names(preprocessor)
    x_train_transformed = pd.DataFrame(x_train_transformed,columns=new_col_names)
    x_test_transformed = pd.DataFrame(x_test_transformed,columns=new_col_names)

    model = CatBoostClassifier(iterations = 2000, random_state=random_state,)
    model.fit(x_train_transformed, y_train, eval_set=(x_test_transformed, y_test) , use_best_model=True, early_stopping_rounds=100, verbose=100) # <- x_train_transformed (not x_train)
    
    y_pred_proba = model.predict_proba(x_test_transformed)
    y_pred = model.predict(x_test_transformed) # ì˜ˆì¸¡ ë¼ë²¨
    logloss_history.append(log_loss(y_test,y_pred_proba)) # loglossì¸¡ì • ë° ê¸°ë¡
    accuracy_history.append(accuracy_score(y_pred, y_test)) # ì •í™•ë„ ì¸¡ì • ë° ê¸°ë¡
print("ê° ë¶„í• ì˜ logloss ê¸°ë¡ :", logloss_history)    
print("ê° ë¶„í• ì˜ ì •í™•ë„ ê¸°ë¡ :", accuracy_history)
print("í‰ê·  logloss :", np.mean(logloss_history))
print("í‰ê·  ì •í™•ë„ :", np.mean(accuracy_history))   
```
<p align="center"><img src="./images/CATBOOST_result.png" width="100%" height="100%"></p>

**feature imoprtance**
<p align="center"><img src="./images/feature_importance.png" width="100%" height="100%"></p>


## 04. Deep Learning


```python
logloss_history = []
accuracy_history = []
fold_no = 1
for train_index, test_index in str_kf.split(credit_X, credit_Y):
    X_train, X_test = credit_X.loc[train_index], credit_X.loc[test_index]
    y_train, y_test = credit_Y.loc[train_index], credit_Y.loc[test_index]
    
    x_train_transformed , x_test_transformed, preprocessor = pipe_processing(X_train, X_test)
#     new_col_names = get_feature_names(preprocessor)
#     x_train_transformed = pd.DataFrame(x_train_transformed,columns=new_col_names)
#     x_test_transformed = pd.DataFrame(x_test_transformed,columns=new_col_names)
    train_label = utils.to_categorical(y_train) # 0~2-> one-hot vector
    test_label = utils.to_categorical(y_test) # 0~2 -> one-hot vector
    
    model = models.Sequential() 

    model.add(layers.Flatten())
    model.add(layers.Dense(units=256, activation=None, kernel_initializer=initializers.he_normal())) 
    model.add(layers.BatchNormalization()) # BNì€ ì ìš©í•˜ë ¤ë©´ ë§¤ ë ˆì´ì–´ë§ˆë‹¤ í•´ì£¼ëŠ” ê²ƒì´ ì¢‹ë‹¤.
    model.add(layers.Activation('elu')) # layers.ELU or layers.LeakyReLU

    model.add(layers.Dense(units=512, activation=None, kernel_initializer=initializers.he_normal())) 
    model.add(layers.BatchNormalization())
    model.add(layers.Activation('elu')) # layers.ELU or layers.LeakyReLU

    model.add(layers.Dense(units=256, activation=None, kernel_initializer=initializers.he_normal())) 
    model.add(layers.BatchNormalization())
    model.add(layers.Activation('elu'))
    model.add(layers.Dropout(rate=0.5))

    model.add(layers.Dense(units=256, activation=None, kernel_initializer=initializers.he_normal())) 
    model.add(layers.BatchNormalization())
    model.add(layers.Activation('elu'))
    model.add(layers.Dropout(rate=0.5))

    model.add(layers.Dense(units=3, activation='softmax')) # 0~2 

    model.compile(optimizer=optimizers.RMSprop(),# í•¨ìˆ˜ì— ì¸ìë¡œ learning Rate ì ìš© ê°€ëŠ¥ 
                  loss=losses.categorical_crossentropy, 
                  metrics=[metrics.categorical_accuracy])
    # Generate a print
    print('------------------------------------------------------------------------')
    print(f'Training for fold {fold_no} ...')

    # Fit data to model
    history = model.fit(x_train_transformed, train_label, batch_size=100, epochs=30, verbose = 0) 
    # Generate generalization metrics
    scores = model.evaluate(x_test_transformed, test_label, verbose=0)
    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')
    accuracy_history.append(scores[1] * 100)
    logloss_history.append(scores[0])

    # Increase fold number
    fold_no = fold_no + 1
```
<p align="center"><img src="./images/DL_result.png" width="100%" height="100%"></p>

í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ìœ„í•´ **Keras tuner** í™œìš©
### 04_01. Keras tuner (BayesianOptimization)
```python
tuner = kt.BayesianOptimization(build_hyper_model,
                                objective = kt.Objective('val_loss','min'), # Hyper-params tuningì„ ìœ„í•œ ëª©ì í•¨ìˆ˜ ì„¤ì • (metric to minimize or maximize)
                                max_trials = 30, # ì„œë¡œ ë‹¤ë¥¸ Hyper-params ì¡°í•©ìœ¼ë¡œ ì‹œë„í•  ì´ Trial íšŸìˆ˜ ì„¤ì •
                                directory = 'test_prac_dir', # Path to the working directory
                                project_name = 'Credit_hyper_2(final)') # Name to use as directory name for files saved by this Tuner
```


### 04_01. Keras tuner (Hyperband)
```python
# Hyperband
tuner = kt.Hyperband(model_builder,
                     objective = kt.Objective('val_loss','min'), 
                     max_epochs = 30,
                     factor = 3,
                     directory = 'test_prac_dir', # Path to the working directory
                     project_name = 'Credit_hyperband')
```
